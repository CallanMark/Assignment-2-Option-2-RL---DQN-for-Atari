{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27b581f0",
   "metadata": {},
   "source": [
    "# CS4287 Assignment 2: Deep Reinforcement Learning (Atari)\n",
    "\n",
    "**Team Members:**\n",
    "* **Name:** Raid Mouras\n",
    "* **ID:** 22368566\n",
    "* **Name:** Jason Cushen\n",
    "* **ID:** 22342516\n",
    "* **Name:** Mark Callan\n",
    "* **ID:** 22363246"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f1f4684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.9.0+cu130)\n",
      "Requirement already satisfied: torchvision in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.24.0+cu130)\n",
      "Requirement already satisfied: numpy in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: gymnasium[atari] in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gymnasium[atari]) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gymnasium[atari]) (4.15.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gymnasium[atari]) (0.0.4)\n",
      "Requirement already satisfied: ale_py>=0.9 in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gymnasium[atari]) (0.11.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\raid\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\raid\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\raid\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\raid\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: gymnasium 1.2.2 does not provide the extra 'accept-rom-license'\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "'AutoROM' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "%pip install gymnasium[atari] gymnasium[accept-rom-license] torch torchvision numpy opencv-python matplotlib\n",
    "!AutoROM --accept-license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c36b801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete for: BreakoutNoFrameskip-v4\n",
      "Target Device: cuda\n",
      "âœ… GPU DETECTED: NVIDIA RTX 1000 Ada Generation Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# --- 1. CONFIGURATION (Breakout) ---\n",
    "ENV_NAME = \"BreakoutNoFrameskip-v4\"\n",
    "GAMMA = 0.99                # Discount factor\n",
    "BATCH_SIZE = 32             # Batch size\n",
    "LR = 1e-4                   # Learning Rate\n",
    "EPSILON_START = 1.0         # 100% random actions\n",
    "EPSILON_FINAL = 0.02        # 2% random actions\n",
    "EPSILON_DECAY = 150000      # Exploration frames\n",
    "REPLAY_SIZE = 100000        # Memory size\n",
    "TARGET_UPDATE = 1000        # Network update frequency\n",
    "\n",
    "# --- 2. HARDWARE CHECK ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Setup Complete for: {ENV_NAME}\")\n",
    "print(f\"Target Device: {device}\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(f\"âœ… GPU DETECTED: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"âŒ WARNING: CPU DETECTED.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c98d1673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cell 3 Complete: Preprocessing wrapper defined.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 3: PREPROCESSING (The Eyes) ---\n",
    "\n",
    "class AtariWrapper(gym.Wrapper):\n",
    "    def __init__(self, env, k=4):\n",
    "        super().__init__(env)\n",
    "        self.k = k  # k=4 means we stack 4 frames together to see \"motion\"\n",
    "        self.frames = deque([], maxlen=k)\n",
    "        \n",
    "        # We define what the AI sees: A stack of 4 images, each 84x84 pixels\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0, high=255, shape=(k, 84, 84), dtype=np.uint8\n",
    "        )\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        # Reset the game and fill the stack with the first frame 4 times\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "        processed_frame = self._process(obs)\n",
    "        for _ in range(self.k):\n",
    "            self.frames.append(processed_frame)\n",
    "        return self._get_obs(), info\n",
    "\n",
    "    def step(self, action):\n",
    "        # Play one step, capture the new frame, process it, and add to stack\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        self.frames.append(self._process(obs))\n",
    "        return self._get_obs(), reward, terminated, truncated, info\n",
    "\n",
    "    def _process(self, frame):\n",
    "        # 1. Turn color into Grayscale (Black & White)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        # 2. Shrink to 84x84 pixels (Less data for GPU to crunch)\n",
    "        frame = cv2.resize(frame, (84, 84), interpolation=cv2.INTER_AREA)\n",
    "        return frame\n",
    "\n",
    "    def _get_obs(self):\n",
    "        # Stack frames into a numpy array (4, 84, 84)\n",
    "        return np.array(self.frames)\n",
    "\n",
    "print(\"âœ… Cell 3 Complete: Preprocessing wrapper defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57f72b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cell 4 Complete: Neural Network defined.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 4: THE NETWORK (The Brain) ---\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_shape, num_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        # 1. Convolutional Layers (Visual Cortex)\n",
    "        # These layers \"scan\" the 84x84 images to find patterns (balls, paddles).\n",
    "        self.features = nn.Sequential(\n",
    "            # Conv 1: Scans with an 8x8 filter. Captures big objects.\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Conv 2: Scans with a 4x4 filter. Captures smaller details.\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Conv 3: Scans with a 3x3 filter. Captures fine interactions.\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 2. Fully Connected Layers (Decision Making)\n",
    "        # These layers take the patterns found above and decide \"Left\" or \"Right\".\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7, 512), # 64 filters * 7x7 size = 3136 inputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_actions) # Output: One score for every button\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through the visual layers\n",
    "        x = self.features(x)\n",
    "        # Flatten: Squash the 3D maps into a 1D vector so the linear layers can read it\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Pass through decision layers to get Q-values\n",
    "        return self.fc(x)\n",
    "\n",
    "print(\"âœ… Cell 4 Complete: Neural Network defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce610c19",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameNotFound",
     "evalue": "Environment `BreakoutNoFrameskip` doesn't exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameNotFound\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- CELL 5: THE TRAINING LOOP ---\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 1. Initialize Everything\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m env = \u001b[43mgym\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mENV_NAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m env = AtariWrapper(env) \u001b[38;5;66;03m# Apply our \"Eyes\"\u001b[39;00m\n\u001b[32m      6\u001b[39m agent_net = DQN(env.observation_space.shape, env.action_space.n).to(device) \u001b[38;5;66;03m# The Actor\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Raid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gymnasium\\envs\\registration.py:681\u001b[39m, in \u001b[36mmake\u001b[39m\u001b[34m(id, max_episode_steps, disable_env_checker, **kwargs)\u001b[39m\n\u001b[32m    678\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mid\u001b[39m, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m    680\u001b[39m     \u001b[38;5;66;03m# The environment name can include an unloaded module in \"module:env_name\" style\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m     env_spec = \u001b[43m_find_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(env_spec, EnvSpec)\n\u001b[32m    685\u001b[39m \u001b[38;5;66;03m# Update the env spec kwargs with the `make` kwargs\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Raid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gymnasium\\envs\\registration.py:526\u001b[39m, in \u001b[36m_find_spec\u001b[39m\u001b[34m(env_id)\u001b[39m\n\u001b[32m    520\u001b[39m     logger.warn(\n\u001b[32m    521\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing the latest versioned environment `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_env_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    522\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minstead of the unversioned environment `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    523\u001b[39m     )\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m env_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m     \u001b[43m_check_version_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error.Error(\n\u001b[32m    528\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo registered env with id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Did you register it, or import the package that registers it? Use `gymnasium.pprint_registry()` to see all of the registered environments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    529\u001b[39m     )\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m env_spec\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Raid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gymnasium\\envs\\registration.py:392\u001b[39m, in \u001b[36m_check_version_exists\u001b[39m\u001b[34m(ns, name, version)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m get_env_id(ns, name, version) \u001b[38;5;129;01min\u001b[39;00m registry:\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m \u001b[43m_check_name_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Raid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gymnasium\\envs\\registration.py:369\u001b[39m, in \u001b[36m_check_name_exists\u001b[39m\u001b[34m(ns, name)\u001b[39m\n\u001b[32m    366\u001b[39m namespace_msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m in namespace \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mns\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ns \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    367\u001b[39m suggestion_msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Did you mean: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestion[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`?\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m suggestion \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m error.NameNotFound(\n\u001b[32m    370\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEnvironment `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt exist\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnamespace_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestion_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    371\u001b[39m )\n",
      "\u001b[31mNameNotFound\u001b[39m: Environment `BreakoutNoFrameskip` doesn't exist."
     ]
    }
   ],
   "source": [
    "# --- CELL 5: THE TRAINING LOOP ---\n",
    "\n",
    "# 1. Initialize Everything\n",
    "env = gym.make(ENV_NAME)\n",
    "env = AtariWrapper(env) # Apply our \"Eyes\"\n",
    "agent_net = DQN(env.observation_space.shape, env.action_space.n).to(device) # The Actor\n",
    "target_net = DQN(env.observation_space.shape, env.action_space.n).to(device) # The Reference\n",
    "target_net.load_state_dict(agent_net.state_dict()) # Sync them up\n",
    "optimizer = optim.Adam(agent_net.parameters(), lr=LR)\n",
    "replay_buffer = deque(maxlen=REPLAY_SIZE)\n",
    "\n",
    "steps = 0\n",
    "rewards_history = []\n",
    "\n",
    "print(f\"ðŸš€ TRAINING STARTED on {device}...\")\n",
    "print(\"The agent will play randomly for the first ~20 mins to fill memory.\")\n",
    "\n",
    "# 2. The Loop (We run for 1000 episodes for the start)\n",
    "for episode in range(1000): \n",
    "    state, _ = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        steps += 1\n",
    "        \n",
    "        # --- A. SELECT ACTION (Epsilon Greedy) ---\n",
    "        # Calculate how \"random\" we should be right now\n",
    "        epsilon = EPSILON_FINAL + (EPSILON_START - EPSILON_FINAL) * np.exp(-1. * steps / EPSILON_DECAY)\n",
    "        \n",
    "        if random.random() > epsilon:\n",
    "            # Smart Move: Ask the AI \"What is the best move?\"\n",
    "            with torch.no_grad():\n",
    "                state_t = torch.tensor(state, device=device, dtype=torch.float32).unsqueeze(0) / 255.0\n",
    "                action = agent_net(state_t).argmax().item()\n",
    "        else:\n",
    "            # Random Move: Explore the game\n",
    "            action = env.action_space.sample()\n",
    "            \n",
    "        # --- B. PLAY THE STEP ---\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        # --- C. SAVE TO MEMORY ---\n",
    "        replay_buffer.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        \n",
    "        # --- D. TRAIN (The \"Q-Learning Update\" - 4 Marks) ---\n",
    "        if len(replay_buffer) > BATCH_SIZE:\n",
    "            # 1. Grab a random batch of memories\n",
    "            batch = random.sample(replay_buffer, BATCH_SIZE)\n",
    "            states, actions, rewards, next_states, dones = zip(*batch)\n",
    "            \n",
    "            # 2. Convert to GPU Tensors\n",
    "            states = torch.tensor(np.array(states), device=device, dtype=torch.float32) / 255.0\n",
    "            actions = torch.tensor(actions, device=device, dtype=torch.int64).unsqueeze(1)\n",
    "            rewards = torch.tensor(rewards, device=device, dtype=torch.float32).unsqueeze(1)\n",
    "            next_states = torch.tensor(np.array(next_states), device=device, dtype=torch.float32) / 255.0\n",
    "            dones = torch.tensor(dones, device=device, dtype=torch.float32).unsqueeze(1)\n",
    "            \n",
    "            # 3. Calculate \"Current Q\" (What we thought would happen)\n",
    "            curr_q = agent_net(states).gather(1, actions)\n",
    "            \n",
    "            # 4. Calculate \"Target Q\" (What actually happened + future guess)\n",
    "            with torch.no_grad():\n",
    "                max_next_q = target_net(next_states).max(1)[0].unsqueeze(1)\n",
    "                target_q = rewards + (GAMMA * max_next_q * (1 - dones))\n",
    "                \n",
    "            # 5. Calculate Error and Update Weights\n",
    "            loss = nn.SmoothL1Loss()(curr_q, target_q)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() # <--- This is the actual learning moment\n",
    "            optimizer.step()\n",
    "            \n",
    "        # --- E. UPDATE TARGET NETWORK ---\n",
    "        if steps % TARGET_UPDATE == 0:\n",
    "            target_net.load_state_dict(agent_net.state_dict())\n",
    "\n",
    "    rewards_history.append(total_reward)\n",
    "    \n",
    "    # Print progress every 10 episodes\n",
    "    if episode % 10 == 0:\n",
    "        avg_score = np.mean(rewards_history[-100:])\n",
    "        print(f\"Episode: {episode} | Score: {total_reward} | Avg Score: {avg_score:.2f} | Steps: {steps}\")\n",
    "\n",
    "env.close()\n",
    "print(\"Training Finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
